{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762749e6-b7b2-4cac-bc4c-5ca7e08cc540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f8fc1d2-7d53-4c93-966c-c96332625c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dfca7ba-f293-4fd9-9028-9150741f3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\", on_bad_lines='skip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6385b6-7619-4f64-80ba-1020af193c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47ab5b54-f974-4593-8da3-0e9df025e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(10000, random_state=7) # // as we can see this contains 50k data but for working on small purpose lets take 10k data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1744e1ce-1995-40cc-9c6c-a1070cd383c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29430</th>\n",
       "      <td>I love most movies and I'm a big fan of Sean B...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27750</th>\n",
       "      <td>A film that tends to get buried under prejudic...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47782</th>\n",
       "      <td>Howard Brackett (Kevin Kline) is a teacher who...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>Like 'Singin' in the Rain', 'Cover Girl' has a...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24747</th>\n",
       "      <td>Father of the Pride was the best new show to h...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "29430  I love most movies and I'm a big fan of Sean B...  negative\n",
       "27750  A film that tends to get buried under prejudic...  positive\n",
       "47782  Howard Brackett (Kevin Kline) is a teacher who...  positive\n",
       "10498  Like 'Singin' in the Rain', 'Cover Girl' has a...  negative\n",
       "24747  Father of the Pride was the best new show to h...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ad356eb-1b8b-4642-aa2f-9f0c037559c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 29430 to 42618\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     10000 non-null  object\n",
      " 1   sentiment  10000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 234.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3119898-cdfd-42bf-8a32-53ff37f0e1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    5015\n",
       "negative    4985\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts() # this means using the df methoad we are counting the values of particular column ie how many positives and negatives ?\n",
    "# insight is that this is binary classification positive and negative.!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "160828db-fb6c-481f-8999-c03efe346458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['output'] = df['sentiment'].map({'positive': 1, 'negative': 0}) # here i am converting my sentiment labels from text to numbers so they can be used to train ml model\n",
    "# positive will be 1 and negative will be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00b78202-b94d-44a4-af3a-9421873fb4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output\n",
       "1    5015\n",
       "0    4985\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['output'].value_counts() # again when we check the value count of output dataframe we can see that pos -> 1 & neg -> 0 and mapped correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccf92383-5539-42c3-8255-40fadfc15cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = df.review.apply(lambda x: len(x.split())) # in this we are just calcuating and adding len of the each review contains split will, spllit on the basis of\n",
    "# white spaces and then it will form a list of each word like [\"I\",\"Love\",\"This\",\"Movie\"] -> len 4 like this\n",
    "# here i am doing feature engineering , this means basically small reviews may be not more detailed and vice versa...\n",
    "# word count can be useful for the analyszing the patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a42e2ed6-f23e-4a8d-8d8c-6f87d2f8f8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10000.000000\n",
       "mean       230.031700\n",
       "std        169.784644\n",
       "min         10.000000\n",
       "25%        126.000000\n",
       "50%        172.000000\n",
       "75%        278.000000\n",
       "max       2125.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097cc118-6350-4845-94bf-d8a9710a5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93340561-f095-4a83-9997-34feddc54bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c80619b-4c79-4378-a25c-881dd080f66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download stopwords once\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa11ff37-f06a-4664-a66c-008a92a0eeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aren', 'down', \"we're\", 'doing', 'each', 'haven', \"they've\", 'them', 'why', 'we', 'themselves', 'yours', 'no', \"they're\", \"they'd\", 'both', 'if', \"i'm\", 'be', 'it', 'needn', 'against', 'as', \"he'll\", 'am', 'an', 'can', 'ma', 'a', 'their', 're', 'y', \"you'll\", 'hasn', 'by', 'has', 'nor', 'these', 'having', 'up', \"we'll\", 'some', 'when', \"mustn't\", 'but', 'from', \"he's\", 'being', 'any', 'all', \"didn't\", 'after', \"hasn't\", 'just', \"needn't\", 'does', 'not', 'whom', 'your', 'about', \"wouldn't\", \"couldn't\", 'most', 'below', 'was', 'll', 'did', \"won't\", 'yourself', \"you're\", 'herself', 's', 'hadn', 'are', 'here', 'because', \"doesn't\", 'again', 'hers', 'do', 'he', 'have', 'there', 'until', 'what', \"hadn't\", \"should've\", 'and', 'which', 'only', 'where', 'this', 'during', 't', 'into', \"you'd\", 'our', 'will', 'my', 'myself', 'she', \"we'd\", 'between', 'the', \"he'd\", 'had', \"she'd\", \"it's\", 'shouldn', 'out', \"i'd\", 'didn', \"isn't\", 'too', 'very', 'theirs', 've', 'couldn', 'how', 'in', 'its', \"it'd\", 'few', \"they'll\", 'than', 'were', 'over', 'won', \"shan't\", 'then', 'or', 'don', 'o', 'his', 'isn', 'now', 'those', 'mightn', 'they', 'who', 'me', \"she'll\", 'yourselves', \"it'll\", \"you've\", 'doesn', 'such', 'm', 'himself', \"don't\", 'under', 'been', \"shouldn't\", 'is', 'ain', 'wasn', 'before', 'i', \"i'll\", \"i've\", 'wouldn', 'you', \"we've\", 'off', 'other', 'own', 'at', 'd', 'ours', 'him', 'to', 'with', 'through', 'once', 'same', 'more', 'of', \"wasn't\", 'that', 'further', \"weren't\", 'itself', 'mustn', 'her', 'weren', 'so', \"mightn't\", 'above', \"haven't\", 'shan', 'should', 'while', \"that'll\", 'for', 'on', \"aren't\", \"she's\", 'ourselves'}\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8ee7ff9-4fba-4153-9585-16db8d7b4ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove not\n",
    "stop_words.remove(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3125549f-d5ea-4abe-9bae-3cd6e94ff06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_nt_contractions(text):\n",
    "    # Replace n't with ' not'\n",
    "    # Pattern explanation:\n",
    "    # (\\w+)n\\'t → captures a word ending in n't like wasn't, didn't\n",
    "    # \\1 → inserts the first group (was, did, etc.)\n",
    "    return re.sub(r\"(\\b\\w+)n['’]t\\b\", r\"\\1 not\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "541b494a-1766-4ffc-a3ea-4f9dcb3c1608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I did not like the movie.\n"
     ]
    }
   ],
   "source": [
    "sample = \"I didn't like the movie.\"\n",
    "expanded = expand_nt_contractions(sample)\n",
    "print(expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "852ab221-f8aa-4856-b24e-df523a8db37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # 1. Lowercasing\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "    # 3. Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "\n",
    "    # 4. Remove emojis and special characters (non-ASCII)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "\n",
    "    # 5. Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # 6. Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # 7. Expand nt Contractions\n",
    "    text = expand_nt_contractions(text)\n",
    "\n",
    "    # 8. Remove stopwords\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Join cleaned words\n",
    "    cleaned_text = \" \".join(words)\n",
    "\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c2aab35-65d0-4739-8717-f88efb5cd4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_review'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c24122b-672b-479d-a4c1-c8b0be72ceaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>output</th>\n",
       "      <th>length</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27219</th>\n",
       "      <td>Well, maybe I'm just having a bad run with Hin...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>369</td>\n",
       "      <td>well maybe im bad run hindi movies lately aske...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38844</th>\n",
       "      <td>\"Revenge of the Zombies\" is a pretty weak and ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "      <td>revenge zombies pretty weak barely passable zo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7692</th>\n",
       "      <td>I saw this at the premiere in Melbourne&lt;br /&gt;&lt;...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>saw premiere melbourneit shallow twodimensiona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  output  \\\n",
       "27219  Well, maybe I'm just having a bad run with Hin...  negative       0   \n",
       "38844  \"Revenge of the Zombies\" is a pretty weak and ...  negative       0   \n",
       "7692   I saw this at the premiere in Melbourne<br /><...  negative       0   \n",
       "\n",
       "       length                                     cleaned_review  \n",
       "27219     369  well maybe im bad run hindi movies lately aske...  \n",
       "38844     502  revenge zombies pretty weak barely passable zo...  \n",
       "7692      195  saw premiere melbourneit shallow twodimensiona...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bac8d525-eac0-4b11-a01a-42878551f5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I have copy of this on VHS, I think they (The television networks) should play this every year for the next twenty years. So that we don't forget what was and that we remember not to do the same mistakes again. Like putting some people in the director's chair, where they don't belong. This movie Rappin' is like a vaudevillian musical, for those who can't sing, or act. This movie is as much fun as trying to teach the 'blind' to drive a city bus.<br /><br />John Hood, (Peebles) has just got out of prison and he's headed back to the old neighborhood. In serving time for an all-to-nice crime of necessity, of course. John heads back onto the old street and is greeted by kids dogs old ladies and his peer homeys as they dance and sing all along the way.<br /><br />I would recommend this if I was sentimental, or if in truth someone was smoking medicinal pot prescribed by a doctor for glaucoma. Either way this is a poorly directed, scripted, acted and even produced (I never thought I'd sat that) satire of ghetto life with the 'Hood'. Although, I think the redeeming part of the story, through the wannabe gang fight sequences and the dance numbers, his friends care about their neighbors and want to save the ghetto from being torn down and cleaned up. <br /><br />Forget Sonny spoon, Mario could have won an Oscar for that in comparison to this Rap. Oh well if you find yourself wanting to laugh yourself silly and three-quarters embarrassed, be sure to drink first. <br /><br />And please, watch responsibly. (No stars, better luck next time!)\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[31].review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2eccf995-43dc-4cae-837b-f8bc17411e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'copy vhs think television networks play every year next twenty years dont forget remember not mistakes like putting people directors chair dont belong movie rappin like vaudevillian musical cant sing act movie much fun trying teach blind drive city busjohn hood peebles got prison hes headed back old neighborhood serving time alltonice crime necessity course john heads back onto old street greeted kids dogs old ladies peer homeys dance sing along wayi would recommend sentimental truth someone smoking medicinal pot prescribed doctor glaucoma either way poorly directed scripted acted even produced never thought id sat satire ghetto life hood although think redeeming part story wannabe gang fight sequences dance numbers friends care neighbors want save ghetto torn cleaned forget sonny spoon mario could oscar comparison rap oh well find wanting laugh silly threequarters embarrassed sure drink first please watch responsibly stars better luck next time'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[31].cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb86dfc4-e586-48ae-8887-079d2c41b48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1295cefc-ead2-40b0-ac1c-44431dee6476",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a48947ff-88ca-4bca-b8fa-96100deebe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_para(text):\n",
    "\n",
    "    # Split words\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Get lemmas\n",
    "    lemmas = [lemmatizer.lemmatize(word, pos=\"v\") for word in words]\n",
    "\n",
    "    # Join Lemmas words\n",
    "    lemmatized = \" \".join(lemmas)\n",
    "    return lemmatized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff5bfdca-bf46-4c3c-8768-31979cd2c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalized_review'] = df['cleaned_review'].apply(normalize_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcabc006-bee5-4d61-955c-f04ea8f114e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'copy vhs think television network play every year next twenty years dont forget remember not mistake like put people directors chair dont belong movie rappin like vaudevillian musical cant sing act movie much fun try teach blind drive city busjohn hood peebles get prison hes head back old neighborhood serve time alltonice crime necessity course john head back onto old street greet kid dog old ladies peer homeys dance sing along wayi would recommend sentimental truth someone smoke medicinal pot prescribe doctor glaucoma either way poorly direct script act even produce never think id sit satire ghetto life hood although think redeem part story wannabe gang fight sequence dance number friends care neighbor want save ghetto tear clean forget sonny spoon mario could oscar comparison rap oh well find want laugh silly threequarters embarrass sure drink first please watch responsibly star better luck next time'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[31].normalized_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e5950f3-53b5-4f3f-afd9-6219d15d0120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd08e1c5-8372-4a80-9913-853966d7bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First split: train (70%) and temp (30%)\n",
    "train_df, temp_df = train_test_split(df, train_size=0.7, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1718c6b7-d119-4a60-963d-fcd20416c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Second split: temp into validation (10%) and test (20%)\n",
    "# Since temp is 30%, to split it 1:2 ratio → validation = 1/3, test = 2/3\n",
    "val_df, test_df = train_test_split(temp_df, test_size=2/3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fb7ef97-4226-4505-a3c8-5fd1885ef6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 7000, Val: 1000, Test: 2000\n"
     ]
    }
   ],
   "source": [
    "# Check sizes\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc6f4004-d982-4e9b-a8b8-96ac5fc116b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0976cb1c-fa43-4d52-902f-322e776a32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=3, max_df=0.95)\n",
    "X_train = vectorizer.fit_transform(train_df['normalized_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2aece5e4-0e30-416d-8bd5-3c4d7e44c25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 16174)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cde5152-755d-49f5-a0b9-1e30d2895f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x16174 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 34 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "846c3eb5-7319-4ddc-ad92-f4dc71189e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = vectorizer.transform(val_df['normalized_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73e4c73e-a050-4e36-a40f-97a64f233eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 16174)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f11882a-f235-43f0-bd4e-847dcdd4b6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(test_df['normalized_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f37dac00-4f0c-4f34-afbe-ef5d21098d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 16174)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98b38cf3-897a-4ff8-9dbc-7033a1ec3529",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[\"output\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75f337d6-c322-402e-8dad-7cd0602f6a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = val_df[\"output\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a285426-b60e-47d7-b904-d049cf3b061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df[\"output\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cfed4373-b556-48d8-ab69-fd9ea61dd5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ed1725f-5acc-4964-980a-b8620a41afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range of C values\n",
    "c_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "best_val_acc = 0\n",
    "best_c = None\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85371c2a-a6d0-483a-a8df-2789c1917931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.001 | Validation Accuracy = 83.40%\n",
      "C=0.01 | Validation Accuracy = 85.60%\n",
      "C=0.1 | Validation Accuracy = 87.00%\n",
      "C=1 | Validation Accuracy = 86.00%\n",
      "C=10 | Validation Accuracy = 85.20%\n",
      "C=100 | Validation Accuracy = 85.10%\n"
     ]
    }
   ],
   "source": [
    "for c in c_values:\n",
    "    model = LogisticRegression(C=c, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)*100\n",
    "    print(f\"C={c} | Validation Accuracy = {val_acc:.2f}%\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_c = c\n",
    "        best_model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97c2ee59-b3cc-49fb-a106-0471f715bbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C = 0.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best C = {best_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "60bd64a6-463b-4d86-80a8-02bc99338b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dae6cb2f-be13-4ec9-acbb-2631ba9bffd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 86.00%\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)*100\n",
    "print(f\"Test Accuracy = {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09abe3f2-593a-46af-af73-e2e699afb270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully!\n",
      "Vectorizer features: 16174\n",
      "Best model C value: 0.1\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the vectorizer and the best model\n",
    "joblib.dump(vectorizer, 'bow_vectorizer.pkl')\n",
    "joblib.dump(best_model, 'bow_classifier.pkl')\n",
    "\n",
    "print(\"Models saved successfully!\")\n",
    "print(f\"Vectorizer features: {len(vectorizer.get_feature_names_out())}\")\n",
    "print(f\"Best model C value: {best_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3545e555-a5e7-460f-9f17-b4342240988d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
